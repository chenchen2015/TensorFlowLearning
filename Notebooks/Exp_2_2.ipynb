{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charecter RNN\n",
    "This is my implementation of the Charecter RNN using LSTM and GRU.\n",
    "\n",
    "Example adopted from [TensorFlow Examples](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/recurrent_network.ipynb)\n",
    "\n",
    "Training text is a free eBook from [Project Gutenberg](https://www.gutenberg.org/wiki/Main_Page). The book used is [Frankenstein](https://www.gutenberg.org/ebooks/84)\n",
    "\n",
    "\n",
    "Chen Chen\n",
    "\n",
    "12/15/2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import TensorFlow Module\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import RNN modules\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "\n",
    "# and numpy for math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1 - Feature Representation\n",
    "The choice of how to represent features absolutely critical for the performance. Here I adopted a popular and intuitive choice which simply use a unique integer number to represent a charecter.\n",
    "\n",
    "Given a numerical charecter mapping: \n",
    "\n",
    "<center>$[a, b, c, d, ...] \\rightarrow [0, 1, 2, 3, ...]$</center>\n",
    "\n",
    "any input text block can be represented with a unique sequence of integers:\n",
    "\n",
    "<center>$[\"bed\"] \\rightarrow [1, 4, 3]$</center>\n",
    "\n",
    "The mapping above is pretty intuitive and easy to implement however it's not really good for LSTM network that's using SoftMax and Sigmoidal functions. Since  what we have is basically mapping data from charecters to its **labels**, a numerical encoding of the label isn't really great because it's **continuous**. Therefore, people usually use the so-called **One Hot Encoding** which project the numerical labels into binary:\n",
    "\n",
    "*For example, gven charecter 'e' with a numerical value 4 to represent it's label:*\n",
    "\n",
    "<center>$['e'] \\rightarrow [4] \\rightarrow [0, 0, 0, 0, 1, 0, ...]'$</center>\n",
    "\n",
    "where the total length of the feature array **$n$**  is the length of the chosen dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text has 421503 charecters\n",
      "Dictionary size: 52\n"
     ]
    }
   ],
   "source": [
    "# Load training text\n",
    "filename = \"./Data/Exp_2_2.txt\"\n",
    "rawText = open(filename).read()\n",
    "\n",
    "# Convert all text to lowercase\n",
    "rawText = rawText.lower()\n",
    "\n",
    "# Create a unique mapping from chars to integers\n",
    "allChars = sorted(list(set(rawText)))\n",
    "charDict = dict( (char, i) for i, char in enumerate(allChars) )\n",
    "\n",
    "# Summarize\n",
    "nText = len(rawText)   # Total number of charecters in the input text\n",
    "nChars = len(allChars) # Total number of unique charecters in the dictionary\n",
    "\n",
    "print(\"Input text has {0} charecters\\nDictionary size: {1}\".format(nText, nChars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Here is an example of the One Hot Encoding\n",
    "# the input array is [0,1,2,3,4] with 5 different labels\n",
    "onehot = tf.one_hot([0,1,2,3,4], 5, 1, 0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of input text samples: 100\n"
     ]
    }
   ],
   "source": [
    "# Break input text into individual training blocks of fixed length\n",
    "# Note that this is a sliding window sampling with a window\n",
    "# width of sampleLen and offset of 1\n",
    "sampleLen = 200\n",
    "dataIn  = []\n",
    "dataOut = []\n",
    "samplesToTake = nText-sampleLen  # the actual end of the range\n",
    "for i in range(0, 100, 1):\n",
    "    sampleIn  = rawText[i : i + sampleLen]\n",
    "    sampleOut = rawText[i + sampleLen]\n",
    "    dataIn.append( [charDict[char] for char in sampleIn] )\n",
    "    dataOut.append( charDict[sampleOut] )\n",
    "\n",
    "# Total number of text samples\n",
    "nSamples = len(dataIn)\n",
    "print(\"Total number of input text samples: {0}\".format(nSamples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the text input to One Hot Encoding\n",
    "\n",
    "# Reshape the sampled text sequences\n",
    "dataX = np.reshape(dataIn, (nSamples, sampleLen))\n",
    "\n",
    "# Normalize the numeric labels (0, 1)\n",
    "dataX = dataX / float(nChars)\n",
    "\n",
    "# Convert to One Hot Encoding\n",
    "dataY = tf.one_hot(dataOut, nChars, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters for RNN\n",
    "\n",
    "# Control Parameters\n",
    "maxIter = 1e3\n",
    "batchSize = 10\n",
    "printStep = 10\n",
    "\n",
    "# RNN Parameters\n",
    "learnRate = 0.001  # Learning rate\n",
    "nHidden = 64      # Number of Hidden Units\n",
    "nClasses = nChars  # Total number of classes. We are predicting single digits from 0-9\n",
    "\n",
    "# TensorFlow Graph Input\n",
    "x = tf.placeholder(tf.float32, [batchSize, sampleLen], name=\"netInput\")\n",
    "y = tf.placeholder(tf.float32, [None, nClasses], name=\"netOutput\")\n",
    "\n",
    "# RNN Weight and Bias Matrix\n",
    "weight = {\n",
    "    'out': tf.Variable(tf.random_normal([nHidden, nClasses]))\n",
    "}\n",
    "bias = {\n",
    "    'out': tf.Variable(tf.random_normal([nClasses]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RNN(x, weight, bias):\n",
    "    # Preprocess data to tensors\n",
    "    # Raw data shape: (batchSize, nSamples, sampleLen)\n",
    "    # Tensor shape  : list of nSamples tensors each with a shape of (batchSize, sampleLen)\n",
    "    \n",
    "    # Permuting batchSize and nRows\n",
    "    #  Variable:   x[batchSize, nSamples, sampleLen]  =>  x[ nSamples, batchSize, sampleLen]\n",
    "    # Dimension:   x[   0     ,     1   ,     2    ]  =>  x[    1    ,     0    ,     2    ]\n",
    "    #x = tf.transpose(x, [1, 0, 2])\n",
    "    # Reshape x to 2D => [batchSize * nSamples, sampleLen]\n",
    "    #x = tf.reshape(x, [-1, sampleLen])\n",
    "    # Split the dimension to get a list of nSamples tensors of shape [batchSize, sampleLen]\n",
    "    x = tf.split(1, sampleLen, x)\n",
    "    \n",
    "    # Define a LSTM cell\n",
    "    lstmCell = rnn_cell.BasicLSTMCell(nHidden, forget_bias=1.0)\n",
    "    \n",
    "    # Get LSTM cell output\n",
    "    outputs, states = rnn.rnn(lstmCell, x, dtype=tf.float32)\n",
    "    \n",
    "    # Linear activation function\n",
    "    return tf.matmul(outputs[-1], weight['out']) + bias['out']\n",
    "\n",
    "# Use the function defined above to convert data into list of tensors\n",
    "# And use LSTM RNN to predict the output\n",
    "predY = RNN(x, weight, bias)\n",
    "\n",
    "# Define cost function and optimizer\n",
    "costFun = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(predY, y))\n",
    "optimizerFun = tf.train.AdamOptimizer(learning_rate=learnRate).minimize(costFun)\n",
    "\n",
    "# Evaluate Model\n",
    "predResult = tf.equal(tf.argmax(predY, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(predResult, tf.float32))\n",
    "\n",
    "# Initializing all variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, or numpy ndarrays.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d284e1008726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[1;31m# Run optimization op (backprop)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizerFun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatchX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatchY\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mprintStep\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Slayer\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Slayer\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             raise TypeError('The value of a feed cannot be a tf.Tensor object. '\n\u001b[0m\u001b[1;32m    925\u001b[0m                             \u001b[1;34m'Acceptable feed values include Python scalars, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m                             'strings, lists, or numpy ndarrays.')\n",
      "\u001b[0;31mTypeError\u001b[0m: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, or numpy ndarrays."
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batchSize < maxIter:\n",
    "        #\n",
    "        batchX = dataX[(step-1)*batchSize : step*batchSize, :]\n",
    "        batchY = dataY[(step-1)*batchSize : step*batchSize, :]\n",
    "        \n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizerFun, feed_dict={x: batchX, y: batchY})\n",
    "        \n",
    "        if step % printStep == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batchX, y: batchY})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(costFun, feed_dict={x: batchX, y: batchY})\n",
    "            print(\"Iter \", str(step*batchSize), \", Minibatch Loss= \",\n",
    "                  \"{:.6f}\".format(loss), \", Training Accuracy= \",\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 10\n",
    "    testData = dataX[:test_len, :]\n",
    "    testLabel = dataY[:test_len, :]\n",
    "    print(\"Testing Accuracy:\",\n",
    "          sess.run(accuracy, feed_dict={x: testData, y: testLabel}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_1:0' shape=(10, 52) dtype=int32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchY"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
