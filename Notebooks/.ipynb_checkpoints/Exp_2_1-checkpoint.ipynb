{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### This is an example implementation of a Recurrent Neural Network (LSTM) using the TensorFlow Library.\n",
    "\n",
    "Example adopted from [TensorFlow Examples](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/recurrent_network.ipynb)\n",
    "\n",
    "\n",
    "Chen Chen\n",
    "\n",
    "12/7/2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow Module\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import RNN modules\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "\n",
    "# and numpy for math\n",
    "import numpy as np\n",
    "\n",
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Extract input data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Control Parameters\n",
    "maxIter = 1e6\n",
    "batchSize = 128\n",
    "printStep = 10\n",
    "\n",
    "# RNN Parameters\n",
    "learnRate = 0.001\n",
    "nInput = 28 # Number of input in each MNIST image (row pixels)\n",
    "nRows = 28\n",
    "nHidden = 128 # Number of Hidden Units\n",
    "nClasses = 10 # Total number of classes. We are predicting single digits from 0-9\n",
    "\n",
    "# TensorFlow Graph Input\n",
    "x = tf.placeholder(tf.float32, [None, nRows, nInput], name=\"netInput\")\n",
    "y = tf.placeholder(tf.float32, [None, nClasses], name=\"netOutput\")\n",
    "\n",
    "# RNN Weight and Bias Matrix\n",
    "weight = {\n",
    "    'out': tf.Variable(tf.random_normal([nHidden, nClasses]))\n",
    "}\n",
    "bias = {\n",
    "    'out': tf.Variable(tf.random_normal([nClasses]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RNN(x, weight, bias):\n",
    "    # Preprocess data to tensors\n",
    "    # Raw data shape: (batchSize, nRows, nInput)\n",
    "    # Tensor shape  : list of nRows tensors each with a shape of (batchSize, nInput)\n",
    "    \n",
    "    # Permuting batchSize and nRows\n",
    "    #  Variable:   x[batchSize, nRows, nInput]  =>  x[ nRows, batchSize, nInput]\n",
    "    # Dimension:   x[   0     ,   1  ,    2  ]  =>  x[   1  ,     0    ,    2  ]\n",
    "    x = tf.transpose(x, [1, 0, 2])\n",
    "    # Reshape x to 2D => [batchSize * nRows, nInput]\n",
    "    x = tf.reshape(x, [-1, nInput])\n",
    "    # Split the dimension to get a list of nRows tensors of shape [batchSize, nInput]\n",
    "    x = tf.split(0, nRows, x)\n",
    "    \n",
    "    # Define a LSTM cell\n",
    "    lstmCell = rnn_cell.BasicLSTMCell(nHidden, forget_bias=1.0)\n",
    "    \n",
    "    # Get LSTM cell output\n",
    "    outputs, states = rnn.rnn(lstmCell, x, dtype=tf.float32)\n",
    "    \n",
    "    # Linear activation function\n",
    "    return tf.matmul(outputs[-1], weight['out']) + bias['out']\n",
    "\n",
    "# Use the function defined above to convert data into list of tensors\n",
    "# And use LSTM RNN to predict the output\n",
    "predY = RNN(x, weight, bias)\n",
    "\n",
    "# Define cost function and optimizer\n",
    "costFun = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(predY, y))\n",
    "optimizerFun = tf.train.AdamOptimizer(learning_rate=learnRate).minimize(costFun)\n",
    "\n",
    "# Evaluate Model\n",
    "predResult = tf.equal(tf.argmax(predY, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(predResult, tf.float32))\n",
    "\n",
    "# Initializing all variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  1280 , Minibatch Loss=  1.590937 , Training Accuracy=  0.45312\n",
      "Iter  2560 , Minibatch Loss=  1.362887 , Training Accuracy=  0.53125\n",
      "Iter  3840 , Minibatch Loss=  1.085207 , Training Accuracy=  0.62500\n",
      "Iter  5120 , Minibatch Loss=  0.857014 , Training Accuracy=  0.70312\n",
      "Iter  6400 , Minibatch Loss=  0.764124 , Training Accuracy=  0.75781\n",
      "Iter  7680 , Minibatch Loss=  1.044456 , Training Accuracy=  0.61719\n",
      "Iter  8960 , Minibatch Loss=  0.754498 , Training Accuracy=  0.78906\n",
      "Iter  10240 , Minibatch Loss=  0.576162 , Training Accuracy=  0.83594\n",
      "Iter  11520 , Minibatch Loss=  0.361728 , Training Accuracy=  0.88281\n",
      "Iter  12800 , Minibatch Loss=  0.632104 , Training Accuracy=  0.78906\n",
      "Iter  14080 , Minibatch Loss=  0.436334 , Training Accuracy=  0.85938\n",
      "Iter  15360 , Minibatch Loss=  0.353112 , Training Accuracy=  0.88281\n",
      "Iter  16640 , Minibatch Loss=  0.394575 , Training Accuracy=  0.89062\n",
      "Iter  17920 , Minibatch Loss=  0.263487 , Training Accuracy=  0.88281\n",
      "Iter  19200 , Minibatch Loss=  0.243811 , Training Accuracy=  0.92188\n",
      "Iter  20480 , Minibatch Loss=  0.174086 , Training Accuracy=  0.94531\n",
      "Iter  21760 , Minibatch Loss=  0.428393 , Training Accuracy=  0.84375\n",
      "Iter  23040 , Minibatch Loss=  0.127200 , Training Accuracy=  0.96875\n",
      "Iter  24320 , Minibatch Loss=  0.365483 , Training Accuracy=  0.89062\n",
      "Iter  25600 , Minibatch Loss=  0.335788 , Training Accuracy=  0.89844\n",
      "Iter  26880 , Minibatch Loss=  0.234729 , Training Accuracy=  0.93750\n",
      "Iter  28160 , Minibatch Loss=  0.204562 , Training Accuracy=  0.93750\n",
      "Iter  29440 , Minibatch Loss=  0.237652 , Training Accuracy=  0.91406\n",
      "Iter  30720 , Minibatch Loss=  0.319450 , Training Accuracy=  0.88281\n",
      "Iter  32000 , Minibatch Loss=  0.208964 , Training Accuracy=  0.93750\n",
      "Iter  33280 , Minibatch Loss=  0.192401 , Training Accuracy=  0.94531\n",
      "Iter  34560 , Minibatch Loss=  0.203279 , Training Accuracy=  0.95312\n",
      "Iter  35840 , Minibatch Loss=  0.159602 , Training Accuracy=  0.93750\n",
      "Iter  37120 , Minibatch Loss=  0.228893 , Training Accuracy=  0.92188\n",
      "Iter  38400 , Minibatch Loss=  0.115245 , Training Accuracy=  0.93750\n",
      "Iter  39680 , Minibatch Loss=  0.132785 , Training Accuracy=  0.94531\n",
      "Iter  40960 , Minibatch Loss=  0.288934 , Training Accuracy=  0.89844\n",
      "Iter  42240 , Minibatch Loss=  0.174442 , Training Accuracy=  0.93750\n",
      "Iter  43520 , Minibatch Loss=  0.103396 , Training Accuracy=  0.96094\n",
      "Iter  44800 , Minibatch Loss=  0.138075 , Training Accuracy=  0.95312\n",
      "Iter  46080 , Minibatch Loss=  0.116384 , Training Accuracy=  0.94531\n",
      "Iter  47360 , Minibatch Loss=  0.231422 , Training Accuracy=  0.92969\n",
      "Iter  48640 , Minibatch Loss=  0.264285 , Training Accuracy=  0.92188\n",
      "Iter  49920 , Minibatch Loss=  0.197984 , Training Accuracy=  0.92969\n",
      "Iter  51200 , Minibatch Loss=  0.108736 , Training Accuracy=  0.96875\n",
      "Iter  52480 , Minibatch Loss=  0.161507 , Training Accuracy=  0.95312\n",
      "Iter  53760 , Minibatch Loss=  0.046634 , Training Accuracy=  0.98438\n",
      "Iter  55040 , Minibatch Loss=  0.192307 , Training Accuracy=  0.94531\n",
      "Iter  56320 , Minibatch Loss=  0.258970 , Training Accuracy=  0.92969\n",
      "Iter  57600 , Minibatch Loss=  0.109942 , Training Accuracy=  0.96094\n",
      "Iter  58880 , Minibatch Loss=  0.048530 , Training Accuracy=  0.98438\n",
      "Iter  60160 , Minibatch Loss=  0.137852 , Training Accuracy=  0.93750\n",
      "Iter  61440 , Minibatch Loss=  0.142197 , Training Accuracy=  0.96875\n",
      "Iter  62720 , Minibatch Loss=  0.103228 , Training Accuracy=  0.98438\n",
      "Iter  64000 , Minibatch Loss=  0.170077 , Training Accuracy=  0.94531\n",
      "Iter  65280 , Minibatch Loss=  0.132934 , Training Accuracy=  0.94531\n",
      "Iter  66560 , Minibatch Loss=  0.224387 , Training Accuracy=  0.92188\n",
      "Iter  67840 , Minibatch Loss=  0.094850 , Training Accuracy=  0.96875\n",
      "Iter  69120 , Minibatch Loss=  0.075104 , Training Accuracy=  0.98438\n",
      "Iter  70400 , Minibatch Loss=  0.082088 , Training Accuracy=  0.98438\n",
      "Iter  71680 , Minibatch Loss=  0.082132 , Training Accuracy=  0.98438\n",
      "Iter  72960 , Minibatch Loss=  0.163575 , Training Accuracy=  0.95312\n",
      "Iter  74240 , Minibatch Loss=  0.099719 , Training Accuracy=  0.96875\n",
      "Iter  75520 , Minibatch Loss=  0.091164 , Training Accuracy=  0.96875\n",
      "Iter  76800 , Minibatch Loss=  0.090230 , Training Accuracy=  0.97656\n",
      "Iter  78080 , Minibatch Loss=  0.101501 , Training Accuracy=  0.95312\n",
      "Iter  79360 , Minibatch Loss=  0.112156 , Training Accuracy=  0.95312\n",
      "Iter  80640 , Minibatch Loss=  0.075525 , Training Accuracy=  0.98438\n",
      "Iter  81920 , Minibatch Loss=  0.092003 , Training Accuracy=  0.98438\n",
      "Iter  83200 , Minibatch Loss=  0.112089 , Training Accuracy=  0.95312\n",
      "Iter  84480 , Minibatch Loss=  0.125899 , Training Accuracy=  0.96094\n",
      "Iter  85760 , Minibatch Loss=  0.140852 , Training Accuracy=  0.96875\n",
      "Iter  87040 , Minibatch Loss=  0.084281 , Training Accuracy=  0.98438\n",
      "Iter  88320 , Minibatch Loss=  0.131853 , Training Accuracy=  0.95312\n",
      "Iter  89600 , Minibatch Loss=  0.069941 , Training Accuracy=  0.98438\n",
      "Iter  90880 , Minibatch Loss=  0.128623 , Training Accuracy=  0.95312\n",
      "Iter  92160 , Minibatch Loss=  0.060248 , Training Accuracy=  0.98438\n",
      "Iter  93440 , Minibatch Loss=  0.073262 , Training Accuracy=  0.96875\n",
      "Iter  94720 , Minibatch Loss=  0.059474 , Training Accuracy=  0.98438\n",
      "Iter  96000 , Minibatch Loss=  0.124377 , Training Accuracy=  0.95312\n",
      "Iter  97280 , Minibatch Loss=  0.065438 , Training Accuracy=  0.97656\n",
      "Iter  98560 , Minibatch Loss=  0.111423 , Training Accuracy=  0.97656\n",
      "Iter  99840 , Minibatch Loss=  0.081731 , Training Accuracy=  0.97656\n",
      "Iter  101120 , Minibatch Loss=  0.082526 , Training Accuracy=  0.97656\n",
      "Iter  102400 , Minibatch Loss=  0.077210 , Training Accuracy=  0.99219\n",
      "Iter  103680 , Minibatch Loss=  0.163564 , Training Accuracy=  0.92969\n",
      "Iter  104960 , Minibatch Loss=  0.115325 , Training Accuracy=  0.96875\n",
      "Iter  106240 , Minibatch Loss=  0.154991 , Training Accuracy=  0.95312\n",
      "Iter  107520 , Minibatch Loss=  0.062832 , Training Accuracy=  0.97656\n",
      "Iter  108800 , Minibatch Loss=  0.036771 , Training Accuracy=  0.99219\n",
      "Iter  110080 , Minibatch Loss=  0.149370 , Training Accuracy=  0.96094\n",
      "Iter  111360 , Minibatch Loss=  0.053910 , Training Accuracy=  0.99219\n",
      "Iter  112640 , Minibatch Loss=  0.045043 , Training Accuracy=  0.99219\n",
      "Iter  113920 , Minibatch Loss=  0.027264 , Training Accuracy=  1.00000\n",
      "Iter  115200 , Minibatch Loss=  0.209545 , Training Accuracy=  0.95312\n",
      "Iter  116480 , Minibatch Loss=  0.050196 , Training Accuracy=  0.99219\n",
      "Iter  117760 , Minibatch Loss=  0.028189 , Training Accuracy=  0.99219\n",
      "Iter  119040 , Minibatch Loss=  0.031606 , Training Accuracy=  0.99219\n",
      "Iter  120320 , Minibatch Loss=  0.072588 , Training Accuracy=  0.97656\n",
      "Iter  121600 , Minibatch Loss=  0.157095 , Training Accuracy=  0.93750\n",
      "Iter  122880 , Minibatch Loss=  0.136556 , Training Accuracy=  0.96094\n",
      "Iter  124160 , Minibatch Loss=  0.048061 , Training Accuracy=  0.99219\n",
      "Iter  125440 , Minibatch Loss=  0.053178 , Training Accuracy=  0.98438\n",
      "Iter  126720 , Minibatch Loss=  0.054369 , Training Accuracy=  0.98438\n",
      "Iter  128000 , Minibatch Loss=  0.135423 , Training Accuracy=  0.97656\n",
      "Iter  129280 , Minibatch Loss=  0.053872 , Training Accuracy=  0.99219\n",
      "Iter  130560 , Minibatch Loss=  0.095610 , Training Accuracy=  0.96875\n",
      "Iter  131840 , Minibatch Loss=  0.019259 , Training Accuracy=  1.00000\n",
      "Iter  133120 , Minibatch Loss=  0.025431 , Training Accuracy=  0.99219\n",
      "Iter  134400 , Minibatch Loss=  0.050003 , Training Accuracy=  0.98438\n",
      "Iter  135680 , Minibatch Loss=  0.045350 , Training Accuracy=  0.99219\n",
      "Iter  136960 , Minibatch Loss=  0.044234 , Training Accuracy=  0.97656\n",
      "Iter  138240 , Minibatch Loss=  0.048619 , Training Accuracy=  0.97656\n",
      "Iter  139520 , Minibatch Loss=  0.073142 , Training Accuracy=  0.98438\n",
      "Iter  140800 , Minibatch Loss=  0.050808 , Training Accuracy=  0.97656\n",
      "Iter  142080 , Minibatch Loss=  0.098382 , Training Accuracy=  0.96094\n",
      "Iter  143360 , Minibatch Loss=  0.063142 , Training Accuracy=  0.97656\n",
      "Iter  144640 , Minibatch Loss=  0.072736 , Training Accuracy=  0.98438\n",
      "Iter  145920 , Minibatch Loss=  0.041999 , Training Accuracy=  0.99219\n",
      "Iter  147200 , Minibatch Loss=  0.043193 , Training Accuracy=  0.98438\n",
      "Iter  148480 , Minibatch Loss=  0.082749 , Training Accuracy=  0.95312\n",
      "Iter  149760 , Minibatch Loss=  0.069822 , Training Accuracy=  0.98438\n",
      "Iter  151040 , Minibatch Loss=  0.089859 , Training Accuracy=  0.96875\n",
      "Iter  152320 , Minibatch Loss=  0.080963 , Training Accuracy=  0.96875\n",
      "Iter  153600 , Minibatch Loss=  0.035633 , Training Accuracy=  0.99219\n",
      "Iter  154880 , Minibatch Loss=  0.060608 , Training Accuracy=  0.97656\n",
      "Iter  156160 , Minibatch Loss=  0.028853 , Training Accuracy=  0.99219\n",
      "Iter  157440 , Minibatch Loss=  0.094891 , Training Accuracy=  0.97656\n",
      "Iter  158720 , Minibatch Loss=  0.068650 , Training Accuracy=  0.96875\n",
      "Iter  160000 , Minibatch Loss=  0.067695 , Training Accuracy=  0.98438\n",
      "Iter  161280 , Minibatch Loss=  0.062110 , Training Accuracy=  0.98438\n",
      "Iter  162560 , Minibatch Loss=  0.032422 , Training Accuracy=  0.99219\n",
      "Iter  163840 , Minibatch Loss=  0.041036 , Training Accuracy=  0.99219\n",
      "Iter  165120 , Minibatch Loss=  0.078402 , Training Accuracy=  0.97656\n",
      "Iter  166400 , Minibatch Loss=  0.093547 , Training Accuracy=  0.97656\n",
      "Iter  167680 , Minibatch Loss=  0.038249 , Training Accuracy=  0.99219\n",
      "Iter  168960 , Minibatch Loss=  0.023984 , Training Accuracy=  1.00000\n",
      "Iter  170240 , Minibatch Loss=  0.032517 , Training Accuracy=  0.99219\n",
      "Iter  171520 , Minibatch Loss=  0.045156 , Training Accuracy=  0.97656\n",
      "Iter  172800 , Minibatch Loss=  0.045250 , Training Accuracy=  0.99219\n",
      "Iter  174080 , Minibatch Loss=  0.035448 , Training Accuracy=  0.99219\n",
      "Iter  175360 , Minibatch Loss=  0.041284 , Training Accuracy=  0.99219\n",
      "Iter  176640 , Minibatch Loss=  0.030870 , Training Accuracy=  0.99219\n",
      "Iter  177920 , Minibatch Loss=  0.023784 , Training Accuracy=  0.99219\n",
      "Iter  179200 , Minibatch Loss=  0.030468 , Training Accuracy=  0.99219\n",
      "Iter  180480 , Minibatch Loss=  0.082955 , Training Accuracy=  0.96094\n",
      "Iter  181760 , Minibatch Loss=  0.033919 , Training Accuracy=  0.99219\n",
      "Iter  183040 , Minibatch Loss=  0.056541 , Training Accuracy=  0.99219\n",
      "Iter  184320 , Minibatch Loss=  0.087397 , Training Accuracy=  0.97656\n",
      "Iter  185600 , Minibatch Loss=  0.050111 , Training Accuracy=  0.98438\n",
      "Iter  186880 , Minibatch Loss=  0.019705 , Training Accuracy=  1.00000\n",
      "Iter  188160 , Minibatch Loss=  0.124417 , Training Accuracy=  0.96875\n",
      "Iter  189440 , Minibatch Loss=  0.065945 , Training Accuracy=  0.98438\n",
      "Iter  190720 , Minibatch Loss=  0.027883 , Training Accuracy=  0.99219\n",
      "Iter  192000 , Minibatch Loss=  0.033774 , Training Accuracy=  0.98438\n",
      "Iter  193280 , Minibatch Loss=  0.049648 , Training Accuracy=  0.98438\n",
      "Iter  194560 , Minibatch Loss=  0.028953 , Training Accuracy=  0.99219\n",
      "Iter  195840 , Minibatch Loss=  0.044958 , Training Accuracy=  0.97656\n",
      "Iter  197120 , Minibatch Loss=  0.101188 , Training Accuracy=  0.95312\n",
      "Iter  198400 , Minibatch Loss=  0.060897 , Training Accuracy=  0.97656\n",
      "Iter  199680 , Minibatch Loss=  0.110475 , Training Accuracy=  0.96094\n",
      "Iter  200960 , Minibatch Loss=  0.045376 , Training Accuracy=  0.97656\n",
      "Iter  202240 , Minibatch Loss=  0.035192 , Training Accuracy=  0.99219\n",
      "Iter  203520 , Minibatch Loss=  0.040031 , Training Accuracy=  0.99219\n",
      "Iter  204800 , Minibatch Loss=  0.019483 , Training Accuracy=  1.00000\n",
      "Iter  206080 , Minibatch Loss=  0.045945 , Training Accuracy=  0.98438\n",
      "Iter  207360 , Minibatch Loss=  0.076797 , Training Accuracy=  0.98438\n",
      "Iter  208640 , Minibatch Loss=  0.018766 , Training Accuracy=  1.00000\n",
      "Iter  209920 , Minibatch Loss=  0.033359 , Training Accuracy=  0.99219\n",
      "Iter  211200 , Minibatch Loss=  0.086351 , Training Accuracy=  0.98438\n",
      "Iter  212480 , Minibatch Loss=  0.042725 , Training Accuracy=  0.98438\n",
      "Iter  213760 , Minibatch Loss=  0.017726 , Training Accuracy=  0.99219\n",
      "Iter  215040 , Minibatch Loss=  0.029181 , Training Accuracy=  0.99219\n",
      "Iter  216320 , Minibatch Loss=  0.026325 , Training Accuracy=  0.99219\n",
      "Iter  217600 , Minibatch Loss=  0.038804 , Training Accuracy=  0.98438\n",
      "Iter  218880 , Minibatch Loss=  0.036016 , Training Accuracy=  0.98438\n",
      "Iter  220160 , Minibatch Loss=  0.037524 , Training Accuracy=  0.97656\n",
      "Iter  221440 , Minibatch Loss=  0.060040 , Training Accuracy=  0.97656\n",
      "Iter  222720 , Minibatch Loss=  0.059113 , Training Accuracy=  0.98438\n",
      "Iter  224000 , Minibatch Loss=  0.050118 , Training Accuracy=  0.99219\n",
      "Iter  225280 , Minibatch Loss=  0.024012 , Training Accuracy=  0.99219\n",
      "Iter  226560 , Minibatch Loss=  0.034562 , Training Accuracy=  0.97656\n",
      "Iter  227840 , Minibatch Loss=  0.066932 , Training Accuracy=  0.95312\n",
      "Iter  229120 , Minibatch Loss=  0.029796 , Training Accuracy=  0.98438\n",
      "Iter  230400 , Minibatch Loss=  0.078617 , Training Accuracy=  0.99219\n",
      "Iter  231680 , Minibatch Loss=  0.008665 , Training Accuracy=  1.00000\n",
      "Iter  232960 , Minibatch Loss=  0.033672 , Training Accuracy=  0.99219\n",
      "Iter  234240 , Minibatch Loss=  0.020015 , Training Accuracy=  1.00000\n",
      "Iter  235520 , Minibatch Loss=  0.066362 , Training Accuracy=  0.97656\n",
      "Iter  236800 , Minibatch Loss=  0.084062 , Training Accuracy=  0.96094\n",
      "Iter  238080 , Minibatch Loss=  0.026752 , Training Accuracy=  0.99219\n",
      "Iter  239360 , Minibatch Loss=  0.024966 , Training Accuracy=  1.00000\n",
      "Iter  240640 , Minibatch Loss=  0.019562 , Training Accuracy=  0.99219\n",
      "Iter  241920 , Minibatch Loss=  0.055319 , Training Accuracy=  0.97656\n",
      "Iter  243200 , Minibatch Loss=  0.055317 , Training Accuracy=  0.98438\n",
      "Iter  244480 , Minibatch Loss=  0.042625 , Training Accuracy=  0.99219\n",
      "Iter  245760 , Minibatch Loss=  0.019759 , Training Accuracy=  0.99219\n",
      "Iter  247040 , Minibatch Loss=  0.012172 , Training Accuracy=  1.00000\n",
      "Iter  248320 , Minibatch Loss=  0.025260 , Training Accuracy=  0.99219\n",
      "Iter  249600 , Minibatch Loss=  0.050906 , Training Accuracy=  0.98438\n",
      "Iter  250880 , Minibatch Loss=  0.065698 , Training Accuracy=  0.96875\n",
      "Iter  252160 , Minibatch Loss=  0.039780 , Training Accuracy=  0.97656\n",
      "Iter  253440 , Minibatch Loss=  0.040743 , Training Accuracy=  0.98438\n",
      "Iter  254720 , Minibatch Loss=  0.134614 , Training Accuracy=  0.96875\n",
      "Iter  256000 , Minibatch Loss=  0.003428 , Training Accuracy=  1.00000\n",
      "Iter  257280 , Minibatch Loss=  0.073133 , Training Accuracy=  0.96875\n",
      "Iter  258560 , Minibatch Loss=  0.024471 , Training Accuracy=  0.99219\n",
      "Iter  259840 , Minibatch Loss=  0.030854 , Training Accuracy=  0.98438\n",
      "Iter  261120 , Minibatch Loss=  0.123519 , Training Accuracy=  0.96875\n",
      "Iter  262400 , Minibatch Loss=  0.036531 , Training Accuracy=  0.98438\n",
      "Iter  263680 , Minibatch Loss=  0.071147 , Training Accuracy=  0.97656\n",
      "Iter  264960 , Minibatch Loss=  0.076573 , Training Accuracy=  0.96875\n",
      "Iter  266240 , Minibatch Loss=  0.048122 , Training Accuracy=  0.99219\n",
      "Iter  267520 , Minibatch Loss=  0.055444 , Training Accuracy=  0.98438\n",
      "Iter  268800 , Minibatch Loss=  0.039121 , Training Accuracy=  0.99219\n",
      "Iter  270080 , Minibatch Loss=  0.042964 , Training Accuracy=  0.98438\n",
      "Iter  271360 , Minibatch Loss=  0.028885 , Training Accuracy=  0.98438\n",
      "Iter  272640 , Minibatch Loss=  0.017504 , Training Accuracy=  0.99219\n",
      "Iter  273920 , Minibatch Loss=  0.016745 , Training Accuracy=  1.00000\n",
      "Iter  275200 , Minibatch Loss=  0.050992 , Training Accuracy=  0.99219\n",
      "Iter  276480 , Minibatch Loss=  0.017454 , Training Accuracy=  1.00000\n",
      "Iter  277760 , Minibatch Loss=  0.113995 , Training Accuracy=  0.99219\n",
      "Iter  279040 , Minibatch Loss=  0.102314 , Training Accuracy=  0.96875\n",
      "Iter  280320 , Minibatch Loss=  0.058625 , Training Accuracy=  0.96875\n",
      "Iter  281600 , Minibatch Loss=  0.058842 , Training Accuracy=  0.98438\n",
      "Iter  282880 , Minibatch Loss=  0.014635 , Training Accuracy=  0.99219\n",
      "Iter  284160 , Minibatch Loss=  0.042938 , Training Accuracy=  0.99219\n",
      "Iter  285440 , Minibatch Loss=  0.034539 , Training Accuracy=  0.99219\n",
      "Iter  286720 , Minibatch Loss=  0.067480 , Training Accuracy=  0.97656\n",
      "Iter  288000 , Minibatch Loss=  0.050781 , Training Accuracy=  0.98438\n",
      "Iter  289280 , Minibatch Loss=  0.054887 , Training Accuracy=  0.97656\n",
      "Iter  290560 , Minibatch Loss=  0.004153 , Training Accuracy=  1.00000\n",
      "Iter  291840 , Minibatch Loss=  0.011550 , Training Accuracy=  0.99219\n",
      "Iter  293120 , Minibatch Loss=  0.063094 , Training Accuracy=  0.97656\n",
      "Iter  294400 , Minibatch Loss=  0.032893 , Training Accuracy=  0.98438\n",
      "Iter  295680 , Minibatch Loss=  0.070683 , Training Accuracy=  0.98438\n",
      "Iter  296960 , Minibatch Loss=  0.010365 , Training Accuracy=  1.00000\n",
      "Iter  298240 , Minibatch Loss=  0.045298 , Training Accuracy=  0.98438\n",
      "Iter  299520 , Minibatch Loss=  0.040171 , Training Accuracy=  0.99219\n",
      "Iter  300800 , Minibatch Loss=  0.008909 , Training Accuracy=  1.00000\n",
      "Iter  302080 , Minibatch Loss=  0.014358 , Training Accuracy=  1.00000\n",
      "Iter  303360 , Minibatch Loss=  0.057734 , Training Accuracy=  0.96875\n",
      "Iter  304640 , Minibatch Loss=  0.065895 , Training Accuracy=  0.98438\n",
      "Iter  305920 , Minibatch Loss=  0.015212 , Training Accuracy=  0.99219\n",
      "Iter  307200 , Minibatch Loss=  0.043526 , Training Accuracy=  0.98438\n",
      "Iter  308480 , Minibatch Loss=  0.034766 , Training Accuracy=  0.99219\n",
      "Iter  309760 , Minibatch Loss=  0.016594 , Training Accuracy=  0.99219\n",
      "Iter  311040 , Minibatch Loss=  0.055532 , Training Accuracy=  0.96875\n",
      "Iter  312320 , Minibatch Loss=  0.053951 , Training Accuracy=  0.98438\n",
      "Iter  313600 , Minibatch Loss=  0.055766 , Training Accuracy=  0.98438\n",
      "Iter  314880 , Minibatch Loss=  0.014657 , Training Accuracy=  0.99219\n",
      "Iter  316160 , Minibatch Loss=  0.104853 , Training Accuracy=  0.96875\n",
      "Iter  317440 , Minibatch Loss=  0.034735 , Training Accuracy=  0.98438\n",
      "Iter  318720 , Minibatch Loss=  0.052936 , Training Accuracy=  0.97656\n",
      "Iter  320000 , Minibatch Loss=  0.044718 , Training Accuracy=  0.98438\n",
      "Iter  321280 , Minibatch Loss=  0.056913 , Training Accuracy=  0.97656\n",
      "Iter  322560 , Minibatch Loss=  0.053572 , Training Accuracy=  0.99219\n",
      "Iter  323840 , Minibatch Loss=  0.061988 , Training Accuracy=  0.98438\n",
      "Iter  325120 , Minibatch Loss=  0.080696 , Training Accuracy=  0.98438\n",
      "Iter  326400 , Minibatch Loss=  0.057969 , Training Accuracy=  0.97656\n",
      "Iter  327680 , Minibatch Loss=  0.024646 , Training Accuracy=  0.99219\n",
      "Iter  328960 , Minibatch Loss=  0.069966 , Training Accuracy=  0.96875\n",
      "Iter  330240 , Minibatch Loss=  0.028077 , Training Accuracy=  0.99219\n",
      "Iter  331520 , Minibatch Loss=  0.008296 , Training Accuracy=  1.00000\n",
      "Iter  332800 , Minibatch Loss=  0.071302 , Training Accuracy=  0.97656\n",
      "Iter  334080 , Minibatch Loss=  0.016178 , Training Accuracy=  0.99219\n",
      "Iter  335360 , Minibatch Loss=  0.012449 , Training Accuracy=  1.00000\n",
      "Iter  336640 , Minibatch Loss=  0.016152 , Training Accuracy=  0.99219\n",
      "Iter  337920 , Minibatch Loss=  0.006842 , Training Accuracy=  1.00000\n",
      "Iter  339200 , Minibatch Loss=  0.029072 , Training Accuracy=  0.99219\n",
      "Iter  340480 , Minibatch Loss=  0.032601 , Training Accuracy=  0.99219\n",
      "Iter  341760 , Minibatch Loss=  0.018580 , Training Accuracy=  1.00000\n",
      "Iter  343040 , Minibatch Loss=  0.009766 , Training Accuracy=  1.00000\n",
      "Iter  344320 , Minibatch Loss=  0.029528 , Training Accuracy=  0.99219\n",
      "Iter  345600 , Minibatch Loss=  0.007938 , Training Accuracy=  1.00000\n",
      "Iter  346880 , Minibatch Loss=  0.013937 , Training Accuracy=  0.99219\n",
      "Iter  348160 , Minibatch Loss=  0.006110 , Training Accuracy=  1.00000\n",
      "Iter  349440 , Minibatch Loss=  0.041617 , Training Accuracy=  0.99219\n",
      "Iter  350720 , Minibatch Loss=  0.041261 , Training Accuracy=  0.98438\n",
      "Iter  352000 , Minibatch Loss=  0.023940 , Training Accuracy=  0.98438\n",
      "Iter  353280 , Minibatch Loss=  0.037385 , Training Accuracy=  0.98438\n",
      "Iter  354560 , Minibatch Loss=  0.049569 , Training Accuracy=  0.97656\n",
      "Iter  355840 , Minibatch Loss=  0.065874 , Training Accuracy=  0.96875\n",
      "Iter  357120 , Minibatch Loss=  0.026257 , Training Accuracy=  0.99219\n",
      "Iter  358400 , Minibatch Loss=  0.022100 , Training Accuracy=  0.99219\n",
      "Iter  359680 , Minibatch Loss=  0.081894 , Training Accuracy=  0.98438\n",
      "Iter  360960 , Minibatch Loss=  0.058173 , Training Accuracy=  0.97656\n",
      "Iter  362240 , Minibatch Loss=  0.018447 , Training Accuracy=  0.99219\n",
      "Iter  363520 , Minibatch Loss=  0.048571 , Training Accuracy=  0.98438\n",
      "Iter  364800 , Minibatch Loss=  0.027818 , Training Accuracy=  0.99219\n",
      "Iter  366080 , Minibatch Loss=  0.029017 , Training Accuracy=  0.99219\n",
      "Iter  367360 , Minibatch Loss=  0.022071 , Training Accuracy=  0.99219\n",
      "Iter  368640 , Minibatch Loss=  0.042028 , Training Accuracy=  0.99219\n",
      "Iter  369920 , Minibatch Loss=  0.016342 , Training Accuracy=  1.00000\n",
      "Iter  371200 , Minibatch Loss=  0.025408 , Training Accuracy=  0.99219\n",
      "Iter  372480 , Minibatch Loss=  0.018720 , Training Accuracy=  0.99219\n",
      "Iter  373760 , Minibatch Loss=  0.026460 , Training Accuracy=  0.99219\n",
      "Iter  375040 , Minibatch Loss=  0.039861 , Training Accuracy=  0.98438\n",
      "Iter  376320 , Minibatch Loss=  0.027717 , Training Accuracy=  0.99219\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batchSize < maxIter:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batchSize)\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "        batch_x = batch_x.reshape((batchSize, nRows, nInput))\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizerFun, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % printStep == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(costFun, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"Iter \", str(step*batchSize), \", Minibatch Loss= \",\n",
    "                  \"{:.6f}\".format(loss), \", Training Accuracy= \",\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, nRows, nInput))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print(\"Testing Accuracy:\",\n",
    "          sess.run(accuracy, feed_dict={x: test_data, y: test_label}))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
